{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import time\n",
    "\n",
    "from adamw import AdamW\n",
    "from scheduler import Scheduler\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../fastai_docs/data')\n",
    "MODEL_PATH = PATH/'models'\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "save_tag = 'imagenet_magenta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGENET_PATH = Path('../data/imagenet-sz/160/train')\n",
    "train_ds = ImageClassificationDataset.from_folder(IMAGENET_PATH)\n",
    "\n",
    "# size,bs = 96,36\n",
    "size,bs = 128,32\n",
    "# size,bs = 256,20\n",
    "\n",
    "# Content Data\n",
    "data_norm,data_denorm = normalize_funcs(*imagenet_stats)\n",
    "train_tds = DatasetTfm(train_ds, tfms=[crop_pad(size=size, is_random=False)], tfm_y=False, size=size, do_crop=True)\n",
    "\n",
    "\n",
    "data = DataBunch.create(train_tds, valid_ds=None, bs=bs, tfms=data_norm)\n",
    "data.valid_dl = None\n",
    "\n",
    "# Style Data\n",
    "\n",
    "STYLE_PATH = PATH/'style/dtd/images'\n",
    "# STYLE_PATH = PATH/'style/dtd/subset'\n",
    "style_ds = ImageClassificationDataset.from_folder(STYLE_PATH)\n",
    "\n",
    "# STYLE_PATH = PATH/'style/pbn/train'\n",
    "# style_ds = ImageClassificationDataset.from_single_folder(STYLE_PATH, ['train'])\n",
    "\n",
    "style_tds = DatasetTfm(style_ds, tfms=[crop_pad(size=size, is_random=False)], tfm_y=False, size=size, do_crop=True)\n",
    "style_data = DataBunch.create(style_tds, valid_ds=None, bs=1, tfms=data_norm)\n",
    "style_data.valid_dl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses\n",
    "def ct_loss(input, target): return F.mse_loss(input,target)\n",
    "\n",
    "def gram(input):\n",
    "        b,c,h,w = input.size()\n",
    "        x = input.view(b, c, -1)\n",
    "        return torch.bmm(x, x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "def gram_loss(input, target): return F.mse_loss(gram(input), gram(target))\n",
    "\n",
    "def tva_loss(y):\n",
    "    w_var = torch.sum(torch.abs(y[:, :, :, :-1] - y[:, :, :, 1:]))\n",
    "    h_var = torch.sum(torch.abs(y[:, :, :-1, :] - y[:, :, 1:, :]))\n",
    "    return w_var + h_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = StyleTransformer()\n",
    "ms = StylePredict.create_inception()\n",
    "m_com = CombinedModel(mt, ms).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer ids:  [12, 22, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "m_vgg = VGGActivations().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "log_interval = 50\n",
    "\n",
    "optimizer = AdamW(m_com.parameters(), lr=5e-3, betas=(0.9,0.999), weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = Scheduler(optimizer, [{'ep': (0,1), 'lr': (1e-5,5e-4)}, \n",
    "                                  {'ep': (1,2), 'lr': (5e-4,1e-5)},  \n",
    "                                  {'ep': (2,epochs), 'lr': (1e-5,1e-7)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_com.load_state_dict(torch.load(MODEL_PATH/f'model_combined_4_imagenet_256.pth'), strict=False)\n",
    "# m_com.load_state_dict(torch.load(MODEL_PATH/f'model_combined_{save_tag}.pth'), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_wgts = [i*1e9 for i in [10,50,10,1]] # 2,3,4,5\n",
    "c_block = 1 # 1=3\n",
    "ct_wgt = 5e2\n",
    "tva_wgt = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing LR from 1e-05 to 1.001223867922172e-05\n",
      "Min:0.189\tEp1: [1600/1281184]\tcontent: 2.180\tstyle: 210.209\ttva: 0.633\ttotal: 213.023\t simg: 1\n",
      "Min:0.303\tEp1: [3200/1281184]\tcontent: 2.248\tstyle: 175.799\ttva: 0.842\ttotal: 178.890\t simg: 1\n",
      "Min:0.417\tEp1: [4800/1281184]\tcontent: 2.305\tstyle: 155.502\ttva: 1.022\ttotal: 158.828\t simg: 1\n",
      "Min:0.532\tEp1: [6400/1281184]\tcontent: 2.233\tstyle: 109.204\ttva: 0.944\ttotal: 112.382\t simg: 2\n",
      "Min:0.646\tEp1: [8000/1281184]\tcontent: 2.328\tstyle: 94.789\ttva: 1.064\ttotal: 98.180\t simg: 2\n",
      "Min:0.760\tEp1: [9600/1281184]\tcontent: 2.430\tstyle: 84.786\ttva: 1.190\ttotal: 88.405\t simg: 2\n",
      "Min:0.875\tEp1: [11200/1281184]\tcontent: 2.370\tstyle: 46.975\ttva: 1.260\ttotal: 50.605\t simg: 3\n",
      "Min:0.989\tEp1: [12800/1281184]\tcontent: 2.384\tstyle: 42.146\ttva: 1.269\ttotal: 45.799\t simg: 3\n",
      "Min:1.103\tEp1: [14400/1281184]\tcontent: 2.423\tstyle: 38.501\ttva: 1.294\ttotal: 42.218\t simg: 3\n",
      "Min:1.218\tEp1: [16000/1281184]\tcontent: 2.221\tstyle: 80.882\ttva: 2.114\ttotal: 85.217\t simg: 4\n",
      "Min:1.332\tEp1: [17600/1281184]\tcontent: 2.253\tstyle: 61.339\ttva: 2.572\ttotal: 66.164\t simg: 4\n",
      "Min:1.447\tEp1: [19200/1281184]\tcontent: 2.256\tstyle: 48.273\ttva: 2.975\ttotal: 53.504\t simg: 4\n",
      "Min:1.561\tEp1: [20800/1281184]\tcontent: 2.434\tstyle: 46.302\ttva: 2.925\ttotal: 51.661\t simg: 5\n",
      "Min:1.675\tEp1: [22400/1281184]\tcontent: 2.498\tstyle: 34.363\ttva: 3.208\ttotal: 40.068\t simg: 5\n",
      "Min:1.790\tEp1: [24000/1281184]\tcontent: 2.574\tstyle: 28.539\ttva: 3.449\ttotal: 34.562\t simg: 5\n",
      "Min:1.904\tEp1: [25600/1281184]\tcontent: 2.518\tstyle: 145.976\ttva: 2.197\ttotal: 150.691\t simg: 6\n",
      "Min:2.018\tEp1: [27200/1281184]\tcontent: 2.514\tstyle: 122.563\ttva: 1.849\ttotal: 126.926\t simg: 6\n",
      "Min:2.133\tEp1: [28800/1281184]\tcontent: 2.585\tstyle: 108.793\ttva: 1.931\ttotal: 113.309\t simg: 6\n",
      "Min:2.247\tEp1: [30400/1281184]\tcontent: 2.273\tstyle: 17.970\ttva: 3.255\ttotal: 23.498\t simg: 7\n",
      "Min:2.361\tEp1: [32000/1281184]\tcontent: 2.261\tstyle: 12.091\ttva: 3.318\ttotal: 17.670\t simg: 7\n",
      "Min:2.476\tEp1: [33600/1281184]\tcontent: 2.232\tstyle: 10.205\ttva: 3.355\ttotal: 15.793\t simg: 7\n",
      "Min:2.590\tEp1: [35200/1281184]\tcontent: 2.457\tstyle: 39.317\ttva: 3.375\ttotal: 45.149\t simg: 8\n",
      "Min:2.704\tEp1: [36800/1281184]\tcontent: 2.455\tstyle: 35.378\ttva: 3.506\ttotal: 41.340\t simg: 8\n",
      "Min:2.819\tEp1: [38400/1281184]\tcontent: 2.511\tstyle: 33.040\ttva: 3.604\ttotal: 39.155\t simg: 8\n",
      "Min:2.933\tEp1: [40000/1281184]\tcontent: 2.369\tstyle: 5.933\ttva: 3.614\ttotal: 11.916\t simg: 9\n",
      "Min:3.047\tEp1: [41600/1281184]\tcontent: 2.353\tstyle: 3.850\ttva: 3.512\ttotal: 9.714\t simg: 9\n",
      "Min:3.162\tEp1: [43200/1281184]\tcontent: 2.370\tstyle: 3.180\ttva: 3.466\ttotal: 9.017\t simg: 9\n",
      "Min:3.276\tEp1: [44800/1281184]\tcontent: 2.524\tstyle: 131.206\ttva: 1.117\ttotal: 134.847\t simg: 10\n",
      "Min:3.390\tEp1: [46400/1281184]\tcontent: 2.445\tstyle: 94.038\ttva: 0.792\ttotal: 97.275\t simg: 10\n",
      "Min:3.505\tEp1: [48000/1281184]\tcontent: 2.502\tstyle: 83.076\ttva: 0.919\ttotal: 86.496\t simg: 10\n",
      "Min:3.619\tEp1: [49600/1281184]\tcontent: 2.551\tstyle: 31.104\ttva: 2.577\ttotal: 36.232\t simg: 11\n",
      "Min:3.733\tEp1: [51200/1281184]\tcontent: 2.605\tstyle: 13.277\ttva: 2.811\ttotal: 18.694\t simg: 11\n",
      "Min:3.848\tEp1: [52800/1281184]\tcontent: 2.633\tstyle: 10.440\ttva: 2.838\ttotal: 15.911\t simg: 11\n",
      "Min:3.962\tEp1: [54400/1281184]\tcontent: 2.619\tstyle: 38.847\ttva: 3.595\ttotal: 45.060\t simg: 12\n",
      "Min:4.076\tEp1: [56000/1281184]\tcontent: 2.715\tstyle: 32.418\ttva: 3.774\ttotal: 38.907\t simg: 12\n",
      "Min:4.190\tEp1: [57600/1281184]\tcontent: 2.769\tstyle: 28.081\ttva: 3.908\ttotal: 34.758\t simg: 12\n",
      "Min:4.305\tEp1: [59200/1281184]\tcontent: 2.515\tstyle: 61.901\ttva: 3.242\ttotal: 67.658\t simg: 13\n",
      "Min:4.419\tEp1: [60800/1281184]\tcontent: 2.512\tstyle: 53.572\ttva: 3.249\ttotal: 59.332\t simg: 13\n",
      "Min:4.533\tEp1: [62400/1281184]\tcontent: 2.544\tstyle: 49.967\ttva: 3.260\ttotal: 55.771\t simg: 13\n",
      "Min:4.648\tEp1: [64000/1281184]\tcontent: 3.194\tstyle: 55.281\ttva: 1.754\ttotal: 60.229\t simg: 14\n",
      "Min:4.762\tEp1: [65600/1281184]\tcontent: 3.261\tstyle: 40.848\ttva: 1.830\ttotal: 45.939\t simg: 14\n",
      "Min:4.876\tEp1: [67200/1281184]\tcontent: 3.344\tstyle: 34.505\ttva: 1.915\ttotal: 39.764\t simg: 14\n",
      "Min:4.991\tEp1: [68800/1281184]\tcontent: 3.365\tstyle: 134.496\ttva: 2.404\ttotal: 140.265\t simg: 15\n",
      "Min:5.105\tEp1: [70400/1281184]\tcontent: 3.539\tstyle: 110.539\ttva: 2.747\ttotal: 116.826\t simg: 15\n",
      "Min:5.219\tEp1: [72000/1281184]\tcontent: 3.665\tstyle: 94.688\ttva: 3.061\ttotal: 101.414\t simg: 15\n",
      "Min:5.334\tEp1: [73600/1281184]\tcontent: 2.627\tstyle: 9.594\ttva: 3.246\ttotal: 15.467\t simg: 16\n",
      "Min:5.448\tEp1: [75200/1281184]\tcontent: 2.623\tstyle: 5.122\ttva: 3.333\ttotal: 11.078\t simg: 16\n",
      "Min:5.562\tEp1: [76800/1281184]\tcontent: 2.604\tstyle: 4.230\ttva: 3.337\ttotal: 10.171\t simg: 16\n",
      "Min:5.677\tEp1: [78400/1281184]\tcontent: 2.743\tstyle: 19.536\ttva: 4.605\ttotal: 26.884\t simg: 17\n",
      "Min:5.791\tEp1: [80000/1281184]\tcontent: 2.775\tstyle: 15.359\ttva: 4.637\ttotal: 22.771\t simg: 17\n",
      "Min:5.905\tEp1: [81600/1281184]\tcontent: 2.782\tstyle: 13.559\ttva: 4.619\ttotal: 20.960\t simg: 17\n",
      "Min:6.020\tEp1: [83200/1281184]\tcontent: 2.989\tstyle: 56.464\ttva: 2.601\ttotal: 62.053\t simg: 18\n",
      "Min:6.134\tEp1: [84800/1281184]\tcontent: 2.955\tstyle: 38.935\ttva: 2.716\ttotal: 44.606\t simg: 18\n",
      "Min:6.248\tEp1: [86400/1281184]\tcontent: 2.958\tstyle: 31.507\ttva: 2.881\ttotal: 37.346\t simg: 18\n",
      "Min:6.363\tEp1: [88000/1281184]\tcontent: 2.854\tstyle: 55.437\ttva: 5.587\ttotal: 63.879\t simg: 19\n",
      "Min:6.477\tEp1: [89600/1281184]\tcontent: 2.929\tstyle: 36.098\ttva: 6.267\ttotal: 45.294\t simg: 19\n",
      "Min:6.591\tEp1: [91200/1281184]\tcontent: 2.917\tstyle: 30.677\ttva: 6.404\ttotal: 39.998\t simg: 19\n",
      "Min:6.706\tEp1: [92800/1281184]\tcontent: 2.648\tstyle: 84.597\ttva: 5.048\ttotal: 92.292\t simg: 20\n",
      "Min:6.820\tEp1: [94400/1281184]\tcontent: 2.604\tstyle: 61.686\ttva: 5.352\ttotal: 69.642\t simg: 20\n",
      "Min:6.934\tEp1: [96000/1281184]\tcontent: 2.611\tstyle: 45.299\ttva: 5.469\ttotal: 53.379\t simg: 20\n",
      "Min:7.048\tEp1: [97600/1281184]\tcontent: 2.659\tstyle: 31.292\ttva: 4.448\ttotal: 38.400\t simg: 21\n",
      "Min:7.163\tEp1: [99200/1281184]\tcontent: 2.645\tstyle: 24.385\ttva: 4.588\ttotal: 31.618\t simg: 21\n",
      "Min:7.277\tEp1: [100800/1281184]\tcontent: 2.654\tstyle: 21.900\ttva: 4.637\ttotal: 29.191\t simg: 21\n",
      "Min:7.391\tEp1: [102400/1281184]\tcontent: 2.838\tstyle: 42.875\ttva: 1.961\ttotal: 47.675\t simg: 22\n",
      "Min:7.506\tEp1: [104000/1281184]\tcontent: 2.930\tstyle: 33.851\ttva: 2.131\ttotal: 38.913\t simg: 22\n",
      "Min:7.620\tEp1: [105600/1281184]\tcontent: 2.999\tstyle: 29.251\ttva: 2.155\ttotal: 34.405\t simg: 22\n",
      "Min:7.734\tEp1: [107200/1281184]\tcontent: 2.790\tstyle: 69.440\ttva: 4.279\ttotal: 76.509\t simg: 23\n",
      "Min:7.848\tEp1: [108800/1281184]\tcontent: 2.731\tstyle: 48.035\ttva: 4.704\ttotal: 55.470\t simg: 23\n",
      "Min:7.963\tEp1: [110400/1281184]\tcontent: 2.688\tstyle: 38.955\ttva: 4.915\ttotal: 46.558\t simg: 23\n",
      "Min:8.077\tEp1: [112000/1281184]\tcontent: 2.493\tstyle: 27.564\ttva: 2.276\ttotal: 32.333\t simg: 24\n",
      "Min:8.191\tEp1: [113600/1281184]\tcontent: 2.549\tstyle: 18.056\ttva: 2.325\ttotal: 22.930\t simg: 24\n",
      "Min:8.306\tEp1: [115200/1281184]\tcontent: 2.548\tstyle: 14.640\ttva: 2.343\ttotal: 19.532\t simg: 24\n",
      "Min:8.420\tEp1: [116800/1281184]\tcontent: 2.871\tstyle: 315.072\ttva: 8.912\ttotal: 326.854\t simg: 25\n",
      "Min:8.534\tEp1: [118400/1281184]\tcontent: 2.893\tstyle: 220.920\ttva: 9.774\ttotal: 233.587\t simg: 25\n",
      "Min:8.648\tEp1: [120000/1281184]\tcontent: 2.917\tstyle: 184.329\ttva: 10.177\ttotal: 197.424\t simg: 25\n",
      "Min:8.763\tEp1: [121600/1281184]\tcontent: 2.791\tstyle: 28.524\ttva: 6.302\ttotal: 37.617\t simg: 26\n",
      "Min:8.877\tEp1: [123200/1281184]\tcontent: 2.802\tstyle: 17.917\ttva: 6.274\ttotal: 26.993\t simg: 26\n",
      "Min:8.991\tEp1: [124800/1281184]\tcontent: 2.832\tstyle: 14.438\ttva: 6.279\ttotal: 23.548\t simg: 26\n",
      "Min:9.106\tEp1: [126400/1281184]\tcontent: 2.675\tstyle: 41.549\ttva: 1.566\ttotal: 45.790\t simg: 27\n",
      "Min:9.220\tEp1: [128000/1281184]\tcontent: 2.732\tstyle: 33.705\ttva: 1.524\ttotal: 37.961\t simg: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "m_com.train()\n",
    "style_image_count = 0\n",
    "for e in range(epochs):\n",
    "    agg_content_loss = 0.\n",
    "    agg_style_loss = 0.\n",
    "    agg_tva_loss = 0.\n",
    "    count = 0\n",
    "    batch_tot = len(data.train_dl)\n",
    "    for batch_id, (x_con,_) in enumerate(data.train_dl):\n",
    "        scheduler.update_lr(e, batch_id, batch_tot)\n",
    "        \n",
    "        if (batch_id % (log_interval*3) == 0):\n",
    "            try:\n",
    "                x_style,_ = next(it_style)\n",
    "            except:\n",
    "                it_style = iter(style_data.train_dl)\n",
    "                x_style,_ = next(it_style)\n",
    "            style_image_count += 1\n",
    "            \n",
    "        with torch.no_grad(): \n",
    "            style_batch = x_style.repeat(bs,1,1,1)\n",
    "            s_out = m_vgg(style_batch)\n",
    "            style_feat = [s.clone() for s in s_out]\n",
    "            \n",
    "            targ_feat = m_vgg(x_con)[c_block].clone()\n",
    "            \n",
    "        n_batch = x_con.size(0)\n",
    "        count += n_batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = m_com(x_con, x_style)\n",
    "        out,_ = data_norm((out,None))\n",
    "        inp_feat = m_vgg(out)\n",
    "        \n",
    "        closs = [ct_loss(inp_feat[c_block],targ_feat) * ct_wgt]\n",
    "        sloss = [gram_loss(inp,targ)*wgt for inp,targ,wgt in zip(inp_feat, style_feat, style_wgts) if wgt > 0]\n",
    "        tvaloss = tva_loss(out) * tva_wgt\n",
    "        \n",
    "        total_loss = closs + sloss + [tvaloss]\n",
    "        total_loss = sum(total_loss)\n",
    "    \n",
    "        total_loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(m_com.m_tran.parameters(), 10)\n",
    "#         nn.utils.clip_grad_norm_(m_com.m_style.parameters(), 80)\n",
    "        optimizer.step()\n",
    "    \n",
    "        mom = 0.9\n",
    "        agg_content_loss = agg_content_loss*mom + sum(closs).detach().data*(1-mom)\n",
    "        agg_style_loss = agg_style_loss*mom + sum(sloss).detach().data*(1-mom)\n",
    "        agg_tva_loss = agg_tva_loss*mom + tvaloss.detach().data*(1-mom)\n",
    "        agg_total_loss = (agg_content_loss + agg_style_loss + agg_tva_loss)\n",
    "        \n",
    "        if (batch_id + 1) % log_interval == 0:\n",
    "            time_elapsed = (time.time() - start)/60\n",
    "            mesg = \"Min:{:.3f}\\tEp{}: [{}/{}]\\tcontent: {:.3f}\\tstyle: {:.3f}\\ttva: {:.3f}\\ttotal: {:.3f}\\t simg: {}\".format(\n",
    "                time_elapsed, e + 1, count, len(data.train_dl)*bs,\n",
    "                              agg_content_loss,\n",
    "                              agg_style_loss,\n",
    "                              agg_tva_loss,\n",
    "                              agg_total_loss,\n",
    "                              style_image_count\n",
    "            )\n",
    "            print(mesg)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_imgs(x_con, x_style, idx=0)\n",
    "    with torch.no_grad(): \n",
    "        out = m_com(x_con, x_style)\n",
    "    Image((out[idx].detach().cpu())).show()\n",
    "    Image(data_denorm(x_con[idx].cpu())).show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
