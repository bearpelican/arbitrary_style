{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import time\n",
    "\n",
    "from adamw import AdamW\n",
    "from scheduler import Scheduler, LRScheduler\n",
    "from models import *\n",
    "from loss import TransferLoss\n",
    "from data import ContentStyleLoader, InputDataset, SimpleDataBunch\n",
    "from dist import DDP, sum_tensor, reduce_tensor, env_world_size, env_rank\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../../data')\n",
    "\n",
    "# MODEL_PATH = Path('/ncluster/models')\n",
    "# MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# save_tag = 'resnet_fastai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = PATH/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "#     parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--phases', type=str, help='Learning rate schedule')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, help='number of data loading workers (default: 8)')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, help='manual epoch number (useful on restarts)')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "    parser.add_argument('--print-freq', '-p', default=5, type=int, help='print every')\n",
    "    parser.add_argument('--dist-url', default='env://', type=str, help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int, help='Used for multi-process training')\n",
    "    return parser\n",
    "\n",
    "args = get_parser().parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_distributed = env_world_size() > 1\n",
    "if args.local_rank > 0:\n",
    "    f = open('/dev/null', 'w')\n",
    "    sys.stdout = f\n",
    "    \n",
    "if is_distributed:\n",
    "    print('Distributed initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=env_world_size())\n",
    "    assert(env_world_size() == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, dist.get_world_size()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size,bs = 96,36\n",
    "# size,bs = 128,32\n",
    "size,bs = 256,2\n",
    "\n",
    "data_norm,data_denorm = normalize_funcs(*imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGENET_PATH = PATH/'imagenet-sz/320/train'\n",
    "# imagenet_files = get_files(IMAGENET_PATH, recurse=True)\n",
    "\n",
    "COCO_PATH = PATH/'coco/resize'\n",
    "coco_files = get_files(COCO_PATH, recurse=True)\n",
    "cont_ds = InputDataset(coco_files)\n",
    "\n",
    "# Content Data\n",
    "cont_tds = DatasetTfm(cont_ds, tfms=[crop_pad(size=size, is_random=False), flip_lr(p=0.5)], tfm_y=False, size=size, do_crop=True)\n",
    "data_sampler = DistributedSampler(cont_tds, num_replicas=env_world_size(), rank=env_rank()) if is_distributed else None\n",
    "cont_dl = DeviceDataLoader.create(cont_tds, tfms=data_norm, num_workers=8, \n",
    "                                   bs=bs, shuffle=(data_sampler is None), sampler=data_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style Data\n",
    "\n",
    "STYLE_PATH_DTD = PATH/'style/dtd/images'\n",
    "dtd_files = get_files(STYLE_PATH_DTD, recurse=True)\n",
    "\n",
    "# STYLE_PATH_PBN = PATH/'style/pbn/train'\n",
    "# pbn_files = get_files(STYLE_PATH_PBN, recurse=True)\n",
    "\n",
    "style_ds = InputDataset(dtd_files)\n",
    "style_tds = DatasetTfm(style_ds, tfms=[crop_pad(size=size, is_random=False), flip_lr(p=0.5)], tfm_y=False, size=size, do_crop=True)\n",
    "style_dl = DeviceDataLoader.create(style_tds, tfms=data_norm, num_workers=8, bs=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = ContentStyleLoader(cont_dl, style_dl)\n",
    "data = SimpleDataBunch(train_dl, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DistributedRecorder(Recorder):\n",
    "    def on_backward_begin(self, smooth_loss:Tensor, **kwargs:Any)->None:\n",
    "        if is_distributed:\n",
    "            metrics = torch.tensor([smooth_loss]).float().cuda()\n",
    "            smooth_loss = reduce_tensor(metrics).cpu().numpy()\n",
    "            \n",
    "        super().on_backward_begin(smooth_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WeightScheduler(Callback):\n",
    "    \"Manage 1-Cycle style training as outlined in Leslie Smith's [paper](https://arxiv.org/pdf/1803.09820.pdf).\"\n",
    "    learn:Learner\n",
    "    loss_func:TransferLoss\n",
    "    cont_phases:Collection[Tuple]\n",
    "    style_phases:Collection[Tuple]\n",
    "\n",
    "    def steps(self, phases):\n",
    "        \"Build anneal schedule for all of the parameters.\"\n",
    "        n_batch = len(self.learn.data.train_dl)\n",
    "        return [Stepper((start,end),ep*n_batch,annealing_linear) for ep,start,end in phases]\n",
    "\n",
    "    def on_train_begin(self, n_epochs:int, **kwargs:Any)->None:\n",
    "        \"Initialize our optimization params based on our annealing schedule.\"\n",
    "        self.style_scheds = list(reversed(self.steps(self.style_phases)))\n",
    "        self.cont_scheds = list(reversed(self.steps(self.cont_phases)))\n",
    "        \n",
    "        self.cur_style = self.style_scheds.pop()\n",
    "        self.cur_cont = self.cont_scheds.pop()\n",
    "\n",
    "    def on_batch_end(self, train, **kwargs:Any)->None:\n",
    "        \"Take one step forward on the annealing schedule for the optim params.\"\n",
    "        if train:\n",
    "            self.loss_func.ct_wgt = self.cur_style.step()\n",
    "            self.loss_func.st_wgt = self.cur_cont.step()\n",
    "            \n",
    "            if self.cur_style.is_done: self.cur_style = self.style_scheds.pop()\n",
    "            if self.cur_cont.is_done: self.cur_cont = self.cont_scheds.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mult = env_world_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "mt = StyleTransformer()\n",
    "ms = StylePredict.create_resnet()\n",
    "# ms = StylePredict.create_inception()\n",
    "m_com = CombinedModel(mt, ms).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_distributed: \n",
    "    m_com = DDP(m_com, device_ids=[args.local_rank], output_device=args.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(AdamW, betas=(0.9,0.999), weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_wgt = 2.5e9\n",
    "ct_wgt = 5e2\n",
    "tva_wgt = 1e-6\n",
    "st_block_wgts = [1,80,200,5] # 2,3,4,5\n",
    "c_block = 1 # 1=3\n",
    "lr_mult = env_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "style_phases = [(2,1e2,st_wgt*3),(epochs,st_wgt,st_wgt)]\n",
    "cont_phases = [(2,ct_wgt,ct_wgt),(2,ct_wgt,ct_wgt*3),(epochs,ct_wgt,ct_wgt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer ids:  [12, 22, 32, 42]\n"
     ]
    }
   ],
   "source": [
    "m_vgg = VGGActivations().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mult = env_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = TransferLoss(m_vgg, ct_wgt, st_wgt, st_block_wgts, tva_wgt, data_norm, c_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(data, m_com, opt_func=opt_func, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sched = partial(WeightScheduler, loss_func=loss_func, cont_phases=cont_phases, style_phases=style_phases)\n",
    "learner.callback_fns = [DistributedRecorder, w_sched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='5638' max='59143', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      9.53% [5638/59143 06:11<58:44 116.9283]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting style\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'style_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/arbitrary_style/training/data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb_c\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit_c\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c52d6ace29c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr_mult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     21\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 162\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/arbitrary_style/training/data.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restarting style'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mit_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mb_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'style_dl' is not defined"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, 1e-5*lr_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "log_interval = 50\n",
    "optimizer = AdamW(m_com.parameters(), lr=1e-5, betas=(0.9,0.999), weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mult = env_world_size()\n",
    "scheduler = LRScheduler(optimizer, [{'ep': (0,1),      'lr': (1e-5*lr_mult,5e-4*lr_mult)}, \n",
    "                                  {'ep': (1,2),      'lr': (5e-4*lr_mult,1e-5*lr_mult)},\n",
    "                                  {'ep': (2,epochs), 'lr': (1e-5*lr_mult,1e-7*lr_mult)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_wgt = 2.5e9\n",
    "ct_wgt = 5e2\n",
    "tva_wgt = 1e-6\n",
    "style_block_wgts = [1,80,200,5] # 2,3,4,5\n",
    "c_block = 1 # 1=3\n",
    "style_wgts = [st_wgt*l for l in style_block_wgts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_com.load_state_dict(torch.load(MODEL_PATH/f'model_combined_4_imagenet_256.pth'), strict=False)\n",
    "m_com.load_state_dict(torch.load(MODEL_PATH/f'{save_tag}.pth'), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "m_com.train()\n",
    "style_image_count = 0\n",
    "for e in range(epochs):\n",
    "    agg_content_loss = 0.\n",
    "    agg_style_loss = 0.\n",
    "    agg_tva_loss = 0.\n",
    "    count = 0\n",
    "    batch_tot = len(train_dl)\n",
    "    for batch_id, (x_con,_) in enumerate(train_dl):\n",
    "        scheduler.update_lr(e, batch_id, batch_tot)\n",
    "        \n",
    "#         if (batch_id % (log_interval*3) == 0):\n",
    "        try:\n",
    "            x_style,_ = next(it_style)\n",
    "            style_image_count += 1\n",
    "        except:\n",
    "            it_style = iter(style_dl)\n",
    "            x_style,_ = next(it_style)\n",
    "            print('Restarting style')\n",
    "            style_image_count = 1\n",
    "            \n",
    "        with torch.no_grad(): \n",
    "            style_batch = x_style.repeat(bs,1,1,1)\n",
    "            s_out = m_vgg(style_batch)\n",
    "            style_feat = [s.clone() for s in s_out]\n",
    "            \n",
    "            targ_feat = m_vgg(x_con)[c_block].clone()\n",
    "            \n",
    "        n_batch = x_con.size(0)\n",
    "        count += n_batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = m_com(x_con, x_style)\n",
    "        out,_ = data_norm((out,None))\n",
    "        inp_feat = m_vgg(out)\n",
    "        \n",
    "        closs = [ct_loss(inp_feat[c_block],targ_feat) * ct_wgt]\n",
    "        sloss = [gram_loss(inp,targ)*wgt for inp,targ,wgt in zip(inp_feat, style_feat, style_wgts) if wgt > 0]\n",
    "        tvaloss = tva_loss(out) * tva_wgt\n",
    "        \n",
    "        total_loss = closs + sloss + [tvaloss]\n",
    "        total_loss = sum(total_loss)\n",
    "    \n",
    "        total_loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(m_com.m_tran.parameters(), 10)\n",
    "#         nn.utils.clip_grad_norm_(m_com.m_style.parameters(), 80)\n",
    "        optimizer.step()\n",
    "    \n",
    "        mom = 0.9\n",
    "        agg_content_loss = agg_content_loss*mom + sum(closs).detach().data*(1-mom)\n",
    "        agg_style_loss = agg_style_loss*mom + sum(sloss).detach().data*(1-mom)\n",
    "        agg_tva_loss = agg_tva_loss*mom + tvaloss.detach().data*(1-mom)\n",
    "        agg_total_loss = (agg_content_loss + agg_style_loss + agg_tva_loss)\n",
    "        \n",
    "        if (batch_id + 1) % log_interval == 0:\n",
    "            time_elapsed = (time.time() - start)/60\n",
    "            b_tot = len(train_dl)\n",
    "            mesg = (f\"MIN:{time_elapsed:.2f}\\tEP[{e+1}]\\tB[{batch_id+1:4}/{b_tot}]\\t\"\n",
    "                    f\"CON:{agg_content_loss:.3f}\\tSTYL:{agg_style_loss:.2f}\\t\"\n",
    "                    f\"TVA:{agg_tva_loss:.2f}\\tTOT:{agg_total_loss:.2f}\\t\"\n",
    "#                     f\"S/CT:{style_image_count:3}/{count:3}\"\n",
    "                   )\n",
    "            print(mesg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_imgs(x_con, x_style, idx=0):\n",
    "    with torch.no_grad(): \n",
    "        out = m_com(x_con, x_style)\n",
    "    fig, axs = plt.subplots(1,3,figsize=(12,4))\n",
    "    Image(data_denorm(x_con[idx].cpu())).show(axs[0])\n",
    "    axs[0].set_title('Content')\n",
    "    axs[1].set_title('Style')\n",
    "    axs[2].set_title('Transfer')\n",
    "    Image(data_denorm(x_style[0].cpu())).show(axs[1])\n",
    "    Image((out[idx].detach().cpu())).show(axs[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_con,_ = next(iter(train_dl))\n",
    "idx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_style,_ = next(iter(style_dl))\n",
    "eval_imgs(x_con, x_style, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_style,_ = next(iter(style_dl))\n",
    "eval_imgs(x_con, x_style, idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
